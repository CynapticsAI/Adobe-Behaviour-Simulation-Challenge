{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3372753,"sourceType":"datasetVersion","datasetId":2033813},{"sourceId":7097978,"sourceType":"datasetVersion","datasetId":4091163}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torchvision.transforms as T\nfrom PIL import Image\nimport os\n\nimport cv2\nimport json\nimport glob\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-12-04T10:56:52.206857Z","iopub.execute_input":"2023-12-04T10:56:52.207298Z","iopub.status.idle":"2023-12-04T10:56:54.662516Z","shell.execute_reply.started":"2023-12-04T10:56:52.207266Z","shell.execute_reply":"2023-12-04T10:56:54.661201Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import requests\nfrom PIL import Image\nfrom io import BytesIO\n\ndef load_image_from_url(url):\n    try:\n        # Send an HTTP request to the URL\n        response = requests.get(url)\n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Open the image using PIL (Pillow) from the response content\n            image = Image.open(BytesIO(response.content))\n            return image\n        else:\n            print(f\"Error: Unable to fetch the image. Status Code: {response.status_code}\")\n            return None\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return None\n\n# Example usage\nurl = \"https://example.com/path/to/your/image.jpg\"\nloaded_image = load_image_from_url(url)\n\nif loaded_image:\n    # Display the image (optional)\n    loaded_image.show()\n\n    # You can also perform further processing on the loaded image here\n    # For example, you can save the image locally or perform some image processing operations.\n    # Example: loaded_image.save(\"local_image.jpg\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T10:53:02.501488Z","iopub.execute_input":"2023-12-04T10:53:02.501988Z","iopub.status.idle":"2023-12-04T10:53:02.976902Z","shell.execute_reply.started":"2023-12-04T10:53:02.501934Z","shell.execute_reply":"2023-12-04T10:53:02.975811Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Error: Unable to fetch the image. Status Code: 404\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_image(img: str) -> torch.Tensor:\n  \n    img = Image.open(img)\n\n    transformed_img = transform_image(img)[:3].unsqueeze(0)\n\n    return transformed_img\n\n\ndef compute_embeddings_inListStore(files: list,model) -> dict:\n    \"\"\"\n    Create an index that contains all of the images in the specified list of files.\n    \"\"\"\n    all_embeddings = {}\n    \n    with torch.no_grad():\n      for i, file in enumerate(tqdm(files)):\n        embeddings = model(load_image(file).to(device))\n\n        all_embeddings[file] = np.array(embeddings[0].cpu().numpy()).reshape(1, -1).tolist()\n\n    with open(\"all_embeddings.json\", \"w\") as f:\n        f.write(json.dumps(all_embeddings))\n\n    return all_embeddings\n\n\ndef compute_embeddings_in_listFormat(imgpath,model):\n    \n    img=load_image(imgpath)\n    with torch.no_grad():\n      \n        embeddings = model(load_image(imgpath).to(device))\n\n        a = np.array(embeddings[0].cpu().numpy()).reshape(1, -1).tolist()\n\n    \n\n    return a\ndef compute_embeddings_in_arrayFormat(imgpath,model):\n    \n    img=load_image(imgpath)\n    with torch.no_grad():\n      \n        embeddings = model(load_image(imgpath).to(device))\n\n#         a = np.array(embeddings[0].cpu().numpy()).reshape(1, -1).tolist()\n\n    \n\n    return embeddings","metadata":{"execution":{"iopub.status.busy":"2023-12-04T11:07:26.577289Z","iopub.execute_input":"2023-12-04T11:07:26.577728Z","iopub.status.idle":"2023-12-04T11:07:26.590007Z","shell.execute_reply.started":"2023-12-04T11:07:26.577692Z","shell.execute_reply":"2023-12-04T11:07:26.588850Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"dinov2_vits14 = torch.hub.load(\"facebookresearch/dinov2\", \"dinov2_vits14\")\ndevice = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\ndinov2_vits14.to(device)\n\n\ndinov2_vitb14 = torch.hub.load(\"facebookresearch/dinov2\", \"dinov2_vitb14\")\n\ndinov2_vitb14.to(device)\ntransform_image = T.Compose([T.ToTensor(), T.Resize(244), T.CenterCrop(224), T.Normalize([0.5], [0.5])])\n\n                            ","metadata":{"execution":{"iopub.status.busy":"2023-12-04T11:06:22.495708Z","iopub.execute_input":"2023-12-04T11:06:22.496394Z","iopub.status.idle":"2023-12-04T11:06:26.408785Z","shell.execute_reply.started":"2023-12-04T11:06:22.496346Z","shell.execute_reply":"2023-12-04T11:06:26.407404Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/facebookresearch_dinov2_main\nUsing cache found in /root/.cache/torch/hub/facebookresearch_dinov2_main\n","output_type":"stream"}]},{"cell_type":"code","source":"compute_embeddings_in_arrayFormat(\"/kaggle/input/pistachio-image-dataset/Pistachio_Image_Dataset/Pistachio_Image_Dataset/Kirmizi_Pistachio/kirmizi (1).jpg\",dinov2_vitb14).shape","metadata":{"execution":{"iopub.status.busy":"2023-12-04T11:08:03.783436Z","iopub.execute_input":"2023-12-04T11:08:03.784749Z","iopub.status.idle":"2023-12-04T11:08:04.318533Z","shell.execute_reply.started":"2023-12-04T11:08:03.784708Z","shell.execute_reply":"2023-12-04T11:08:04.317596Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 768])"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}